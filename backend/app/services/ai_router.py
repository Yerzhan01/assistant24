from __future__ import annotations
"""AI Router - Intent classification and data extraction using Google Gemini with RAG."""
import json
import logging
import time
from datetime import datetime
from typing import Any, Dict, List, Optional, TYPE_CHECKING, Callable, Awaitable
from uuid import UUID

import google.generativeai as genai
from sqlalchemy.ext.asyncio import AsyncSession

from app.core.config import settings
from app.core.i18n import t
from app.modules.base import BaseModule, ModuleResponse
from app.modules.registry import get_registry
from app.services.tracing import TracingService, TraceContext

logger = logging.getLogger("ai_router")


class AIRouter:
    """
    AI Router uses Google Gemini to:
    1. Retrieve relevant context from memory (RAG)
    2. Classify user intent (which module to use)
    3. Extract structured data for the module
    4. Store conversation as memory
    """
    
    def __init__(
        self, 
        db: AsyncSession,
        api_key: Optional[str] = None,
        language: str = "ru",
        enable_rag: bool = True,
        thinking_level: str = None
    ) -> None:
        self.db = db
        self.language = language
        self.enable_rag = enable_rag
        self.thinking_level = thinking_level or settings.gemini_thinking_level
        
        # Configure Gemini
        key = api_key or settings.gemini_api_key
        if key:
            genai.configure(api_key=key)
            
            # Configuration for Intent Classification (Strict JSON)
            # Temperature 0.0 for reproducibility
            # Disable thoughts to prevent JSON corruption
            generation_config = {
                "temperature": 0.0,
                "top_p": 0.8,
                "top_k": 40,
                # "thinking_config": {"include_thoughts": False} # Explicitly disable if supported, or omit
            }

            self.model = genai.GenerativeModel(
                settings.gemini_model,
                generation_config=generation_config
            )
        else:
            self.model = None
    
    def _safe_parse_json(self, text: str) -> Optional[Dict[str, Any]]:
        """
        Safely parse JSON from Gemini response.
        Handles markdown code blocks, malformed JSON, and missing fields.
        Robustly extracts { ... } from text.
        """
        if not text:
            return None
            
        import re
        
        # 1. Clean Markdown
        clean_text = text.strip()
        if "```" in clean_text:
            # Extract content strictly between first ```(json)? and last ```
            match = re.search(r"```(?:json)?\s*([\s\S]*?)\s*```", clean_text)
            if match:
                clean_text = match.group(1).strip()
        
        # 2. Extract JSON object if text contains extra chatter
        # Look for first '{' and last '}'
        start = clean_text.find("{")
        end = clean_text.rfind("}")
        
        if start != -1 and end != -1:
            clean_text = clean_text[start:end+1]
        elif start != -1: # Maybe missing closing brace?
            clean_text = clean_text[start:] + "}" # Attempt repair
            
        # 3. Try parsing
        try:
            result = json.loads(clean_text)
            
            # Validate required structure
            if not isinstance(result, dict):
                logger.warning(f"Gemini returned non-dict JSON: {type(result)}")
                return None
            
            # Ensure 'intents' exists (normalize single intent)
            if "intents" not in result or not isinstance(result.get("intents"), list):
                if "intent" in result:
                    result = {
                        "reasoning": result.get("reasoning", "Normalized single intent"),
                        "intents": [result]
                    }
                else:
                    logger.warning(f"Gemini returned JSON without intents: {result}")
                    return None
            
            # Validate intents
            valid_intents = []
            for intent in result.get("intents", []):
                if isinstance(intent, dict) and intent.get("intent"):
                    valid_intents.append(intent)
            
            if not valid_intents:
                return None
                
            result["intents"] = valid_intents
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON parse error: {e} | Text: {clean_text[:200]}")
            return None
    
    def _apply_whatsapp_priority(self, message: str, result: Dict[str, Any], modules: List[BaseModule]) -> Dict[str, Any]:
        """
        Check if message clearly indicates WhatsApp intent.
        If so, override Gemini's classification to ensure correct routing.
        """
        message_lower = message.lower().strip()
        
        # WhatsApp-specific keywords that MUST route to WhatsApp
        wa_strong_keywords = [
            "–Ω–∞–ø–∏—à–∏ –≤ –≤–∞—Ç—Å–∞–ø", "–Ω–∞–ø–∏—à–∏ –≤ whatsapp", "–Ω–∞–ø–∏—à–∏ –≤ —É–∞—Ç—Å–∞–ø",
            "–æ—Ç–ø—Ä–∞–≤—å –≤ –≤–∞—Ç—Å–∞–ø", "–æ—Ç–ø—Ä–∞–≤—å –≤ whatsapp", "–æ—Ç–ø—Ä–∞–≤—å –≤ —É–∞—Ç—Å–∞–ø",
            "–Ω–∞–ø–∏—à–∏ –µ–º—É", "–Ω–∞–ø–∏—à–∏ –µ–π", "–Ω–∞–ø–∏—à–∏ –µ–º—É –≤ —É–∞—Ç—Å–∞–ø",
            "—á–µ—Ä–µ–∑ —É–∞—Ç—Å–∞–ø", "—á–µ—Ä–µ–∑ –≤–∞—Ç—Å–∞–ø", "—á–µ—Ä–µ–∑ whatsapp"
        ]
        
        # Check for strong keywords first
        for kw in wa_strong_keywords:
            if kw in message_lower:
                logger.info(f"WhatsApp priority override triggered by keyword: {kw}")
                return self._force_whatsapp_intent(message, result)
        
        return result
    
    def _force_whatsapp_intent(self, message: str, original_result: Dict[str, Any]) -> Dict[str, Any]:
        """Force WhatsApp intent with original message for further processing."""
        return {
            "reasoning": f"WhatsApp priority override. Original: {original_result.get('reasoning', 'N/A')}",
            "intents": [{
                "intent": "whatsapp",
                "confidence": 0.95,
                "data": {
                    "action": "send_message",
                    "original_message": message
                }
            }],
            "_meta": original_result.get("_meta", {})
        }

    def _build_system_prompt(
        self, 
        modules: List[BaseModule],
        context: str = "",
        message_history: List[Dict[str, str]] = None
    ) -> str:
        """Build system prompt with instructions from all enabled modules and RAG context."""
        registry = get_registry()
        module_instructions = registry.build_ai_prompt(modules, self.language)
        
        # Format history
        history_str = ""
        if message_history:
            history_lines = []
            for msg in message_history[-5:]: # Last 5 messages
                role = "User" if msg["role"] == "user" else "Assistant"
                history_lines.append(f"{role}: {msg['content']}")
            history_str = "\n".join(history_lines)
        
        if self.language == "kz":
            base_prompt = """
–°—ñ–∑ ‚Äî –∞“õ—ã–ª–¥—ã —Ü–∏—Ñ—Ä–ª—ã“õ —Ö–∞—Ç—à—ã—Å—ã–∑. –ü–∞–π–¥–∞–ª–∞–Ω—É—à—ã–Ω—ã“£ —Å“±—Ä–∞—É—ã–Ω —Ç–∞–ª–¥–∞–ø, –ë–Ü–†–ù–ï–®–ï –Ω–∏–µ—Ç—ñ–Ω (intents) –∞–Ω—ã“õ—Ç–∞“£—ã–∑.

‚õî –ú–ê“¢–´–ó–î–´ –®–ï–ö–¢–ï–£–õ–ï–†:
- –°—ñ–∑ –±–∏–∑–Ω–µ—Å-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç—Å—ñ–∑, –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∫–µ “õ–æ—Å—ã–ª–º–∞“ì–∞–Ω—Å—ã–∑.
- –¢–µ–∫ –ø–∞–π–¥–∞–ª–∞–Ω—É—à—ã –±–µ—Ä–≥–µ–Ω –Ω–µ–º–µ—Å–µ –∂–∞–¥—Ç–∞ (RAG) –±–∞—Ä –¥–µ—Ä–µ–∫—Ç–µ—Ä–º–µ–Ω –∂“±–º—ã—Å —ñ—Å—Ç–µ–π—Å—ñ–∑.
- –í–∞–ª—é—Ç–∞ –±–∞“ì–∞–º–¥–∞—Ä—ã, –∞—É–∞ —Ä–∞–π—ã, –∂–∞“£–∞–ª—ã“õ—Ç–∞—Ä —Ç—É—Ä–∞–ª—ã —Å“±—Ä–∞“õ“õ–∞: "–ú–µ–Ω–¥–µ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∫–µ “õ–æ–ª –∂–µ—Ç—ñ–º–¥—ñ–ª—ñ–∫ –∂–æ“õ, –º–µ–Ω —Ç–µ–∫ —Å—ñ–∑–¥—ñ“£ —ñ—Å—Ç–µ—Ä—ñ“£—ñ–∑–¥—ñ –±–∞—Å“õ–∞—Ä–∞–º—ã–Ω" –¥–µ–ø –∂–∞—É–∞–ø –±–µ—Ä—ñ“£—ñ–∑.
- –ú–µ–¥–∏—Ü–∏–Ω–∞–ª—ã“õ, –∑–∞“£–≥–µ—Ä–ª—ñ–∫ –Ω–µ–º–µ—Å–µ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏—è–ª—ã“õ –∫–µ“£–µ—Å –ë–ï–†–ú–ï“¢–Ü–ó.

–ú–ê“¢–´–ó–î–´: –ü–∞–π–¥–∞–ª–∞–Ω—É—à—ã –±—ñ—Ä —Ö–∞–±–∞—Ä–ª–∞–º–∞–¥–∞ –±—ñ—Ä–Ω–µ—à–µ —Ç–∞–ø—Å—ã—Ä–º–∞ –±–µ—Ä–µ –∞–ª–∞–¥—ã. –ë–ê–†–õ–´“í–´–ù —Ç—ñ–∑—ñ–º–≥–µ “õ–æ—Å—ã“£—ã–∑.

–ù–∏–µ—Ç —Ç“Ø—Ä–ª–µ—Ä—ñ:
{module_list}
- "schedule_meeting" ‚Äî –∫–µ–∑–¥–µ—Å—É “±–π—ã–º–¥–∞—Å—Ç—ã—Ä—É
- "recall" ‚Äî ”©—Ç–∫–µ–Ω –∞“õ–ø–∞—Ä–∞—Ç—Ç—ã –µ—Å–∫–µ —Ç“Ø—Å—ñ—Ä—É

–ê–ª–¥—ã“£“ì—ã –¥–∏–∞–ª–æ–≥:
{history_str}

‚ö†Ô∏è ”ò“¢–ì–Ü–ú–ï –ö–û–ù–¢–ï–ö–°–¢–Ü:
–•–∞–±–∞—Ä–ª–∞–º–∞ —Ç–æ–ª—ã“õ –±–æ–ª–º–∞—Å–∞ ("–∞–ª –±“Ø–≥—ñ–Ω?", "—Ç–∞“ì—ã –∫”©—Ä—Å–µ—Ç"), –∞–ª–¥—ã“£“ì—ã –¥–∏–∞–ª–æ–≥—Ç—ã –ø–∞–π–¥–∞–ª–∞–Ω:
- –ï–≥–µ—Ä –±“±—Ä—ã–Ω —Ç–∞–ø—Å—ã—Ä–º–∞–ª–∞—Ä —Å“±—Ä–∞–ª—Å–∞, "–∞–ª –±“Ø–≥—ñ–Ω?" = –±“Ø–≥—ñ–Ω–≥—ñ —Ç–∞–ø—Å—ã—Ä–º–∞–ª–∞—Ä
- "–ë—ñ—Ä—ñ–Ω—à—ñ–Ω—ñ" / "–°–æ“£“ì—ã—Å—ã–Ω" ‚Äî –∞–ª–¥—ã“£“ì—ã –∂–∞—É–∞–ø—Ç–∞–Ω —ç–ª–µ–º–µ–Ω—Ç

{context_block}

“ö–∞–π—Ç–∞—Ä—É —Ñ–æ—Ä–º–∞—Ç—ã (—Ç–µ–∫ JSON):
{{
  "reasoning": "<—Å—ñ–∑–¥—ñ“£ –ª–æ–≥–∏–∫–∞“£—ã–∑–¥—ã —Ç“Ø—Å—ñ–Ω–¥—ñ—Ä—ñ“£—ñ–∑>",
  "intents": [
    {{
      "intent": "<module_id>",
      "confidence": <0.0-1.0>,
      "data": {{ ... }}
    }}
  ]
}}

–ï–≥–µ—Ä –ë–Ü–†–ù–ï–®–ï –Ω–∏–µ—Ç –±–æ–ª—Å–∞, –±–∞—Ä–ª—ã“ì—ã–Ω intents –º–∞—Å—Å–∏–≤—ñ–Ω–µ “õ–æ—Å—ã“£—ã–∑.
–ú—ã—Å–∞–ª—ã: "–ê—Å—Ö–∞—Ç“õ–∞ 50–∫ —Ç”©–ª–µ–¥—ñ–º, –µ—Ä—Ç–µ“£ –∫–µ–∑–¥–µ—Å—É" -> finance + meeting.

–ï–≥–µ—Ä –Ω–∏–µ—Ç—Ç—ñ –∞–Ω—ã“õ—Ç–∞–π –∞–ª–º–∞—Å–∞“£—ã–∑:
{{
  "reasoning": "–¢–∞–ø—Å—ã—Ä–º–∞ —Ç–∞–±—ã–ª–º–∞–¥—ã",
  "intents": [{{"intent": "unknown", "confidence": 0.0, "data": {{}}}}]
}}

–ü–∞–π–¥–∞–ª–∞–Ω—É—à—ã–Ω—ã“£ –∂–µ—Ä–≥—ñ–ª—ñ–∫—Ç—ñ —É–∞“õ—ã—Ç—ã: {current_datetime}

–ú–æ–¥—É–ª—å–¥–µ—Ä –Ω“±—Å“õ–∞—É–ª–∞—Ä—ã:

{module_instructions}
"""
        else:
            base_prompt = """
–¢—ã ‚Äî —É–º–Ω—ã–π —Ü–∏—Ñ—Ä–æ–≤–æ–π —Å–µ–∫—Ä–µ—Ç–∞—Ä—å. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –æ–ø—Ä–µ–¥–µ–ª–∏ –í–°–ï –Ω–∞–º–µ—Ä–µ–Ω–∏—è (intents).

‚õî –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –û–ì–†–ê–ù–ò–ß–ï–ù–ò–Ø:
- –¢—ã –±–∏–∑–Ω–µ—Å-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, —É —Ç–µ–±—è –ù–ï–¢ –¥–æ—Å—Ç—É–ø–∞ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É.
- –¢—ã —Ä–∞–±–æ—Ç–∞–µ—à—å –¢–û–õ–¨–ö–û —Å –¥–∞–Ω–Ω—ã–º–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–ª–∏ –∏–∑ –ø–∞–º—è—Ç–∏ (RAG).
- –ù–∞ –≤–æ–ø—Ä–æ—Å—ã –æ –∫—É—Ä—Å–∞—Ö –≤–∞–ª—é—Ç, –ø–æ–≥–æ–¥–µ, –Ω–æ–≤–æ—Å—Ç—è—Ö, —Ü–µ–Ω–∞—Ö –∞–∫—Ü–∏–π –æ—Ç–≤–µ—á–∞–π: "–£ –º–µ–Ω—è –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É, —è —É–ø—Ä–∞–≤–ª—è—é —Ç–æ–ª—å–∫–æ –≤–∞—à–∏–º–∏ –¥–µ–ª–∞–º–∏."
- –ù–ï –¥–∞–≤–∞–π –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö, —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –∏–ª–∏ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã—Ö —Å–æ–≤–µ—Ç–æ–≤.
- –ù–ï –ø—Ä–∏–¥—É–º—ã–≤–∞–π –¥–∞–Ω–Ω—ã–µ, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ.

–í–ê–ñ–ù–û: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –º–æ–∂–µ—Ç –¥–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–∞–¥–∞—á –≤ –æ–¥–Ω–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏. –í—ã–¥–µ–ª–∏ –í–°–ï –¥–µ–π—Å—Ç–≤–∏—è.

–í–æ–∑–º–æ–∂–Ω—ã–µ –Ω–∞–º–µ—Ä–µ–Ω–∏—è:
{module_list}
- "schedule_meeting" ‚Äî –æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞—Ç—å –≤—Å—Ç—Ä–µ—á—É
- "recall" ‚Äî –≤—Å–ø–æ–º–Ω–∏—Ç—å –ø—Ä–æ—à–ª—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é

–ü—Ä–µ–¥—ã–¥—É—â–∏–π –¥–∏–∞–ª–æ–≥:
{history_str}

‚ö†Ô∏è –ö–û–ù–¢–ï–ö–°–¢ –†–ê–ó–ì–û–í–û–†–ê:
–ï—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ–ø–æ–ª–Ω–æ–µ ("–∞ —Å–µ–≥–æ–¥–Ω—è?", "–ø–æ–∫–∞–∂–∏ –µ—â–µ", "—É–¥–∞–ª–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ"), –∏—Å–ø–æ–ª—å–∑—É–π –ü–†–ï–î–´–î–£–©–ò–ô –î–ò–ê–õ–û–ì —á—Ç–æ–±—ã –ø–æ–Ω—è—Ç—å –æ —á–µ–º —Ä–µ—á—å:
- –ï—Å–ª–∏ –¥–æ —ç—Ç–æ–≥–æ —Å–ø—Ä–∞—à–∏–≤–∞–ª–∏ –∑–∞–¥–∞—á–∏, "–∞ —Å–µ–≥–æ–¥–Ω—è?" = –∑–∞–¥–∞—á–∏ –Ω–∞ —Å–µ–≥–æ–¥–Ω—è
- –ï—Å–ª–∏ –¥–æ —ç—Ç–æ–≥–æ —Å–ø—Ä–∞—à–∏–≤–∞–ª–∏ –¥–æ–ª–≥–∏, "–ø–æ–∫–∞–∂–∏ –µ—â–µ" = –µ—â–µ –¥–æ–ª–≥–∏
- "–ü–µ—Ä–≤–æ–≥–æ" / "–ü–æ—Å–ª–µ–¥–Ω–µ–≥–æ" ‚Äî —Å—Å—ã–ª–∫–∞ –Ω–∞ —ç–ª–µ–º–µ–Ω—Ç –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –æ—Ç–≤–µ—Ç–∞

{context_block}

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ (—Ç–æ–ª—å–∫–æ JSON):
{{
  "reasoning": "<–æ–±—ä—è—Å–Ω–∏ —Å–≤–æ—é –ª–æ–≥–∏–∫—É: –ø–æ—á–µ–º—É —Ç—ã –≤—ã–¥–µ–ª–∏–ª —ç—Ç–∏ –Ω–∞–º–µ—Ä–µ–Ω–∏—è>",
  "intents": [
    {{
      "intent": "<module_id>",
      "confidence": <0.0-1.0>,
      "data": {{ ... }}
    }}
  ]
}}

–ï—Å–ª–∏ –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ –ù–ï–°–ö–û–õ–¨–ö–û –¥–µ–π—Å—Ç–≤–∏–π, –¥–æ–±–∞–≤—å –í–°–ï –≤ –º–∞—Å—Å–∏–≤ intents.
–ü—Ä–∏–º–µ—Ä: "–ó–∞–ø–ª–∞—Ç–∏–ª –ê—Å—Ö–∞—Ç—É 50–∫ –∑–∞ –≤—Å—Ç—Ä–µ—á—É –∑–∞–≤—Ç—Ä–∞" -> finance + meeting.

–ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ—à—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –Ω–∞–º–µ—Ä–µ–Ω–∏–µ:
{{
  "reasoning": "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∑–∞–¥–∞—á—É",
  "intents": [{{"intent": "unknown", "confidence": 0.0, "data": {{}}}}]
}}

–õ–æ–∫–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {current_datetime}

–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ –º–æ–¥—É–ª—è–º:

{module_instructions}
"""
        
        module_list = ", ".join([m.module_id for m in modules])
        
        # Build context block for RAG
        if context:
            if self.language == "kz":
                context_block = f"–ñ–∞–¥—Ç–∞–Ω —Ç–∞–±—ã–ª“ì–∞–Ω –∞“õ–ø–∞—Ä–∞—Ç:\n{context}"
            else:
                context_block = f"–ù–∞–π–¥–µ–Ω–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –ø–∞–º—è—Ç–∏:\n{context}"
        else:
            context_block = ""
        
        # Use Kazakhstan timezone (UTC+5) for user-facing datetime
        # TODO: In production, get timezone from Tenant settings
        from datetime import timezone, timedelta
        kz_tz = timezone(timedelta(hours=5))
        local_now = datetime.now(kz_tz)
        
        return base_prompt.format(
            module_list=module_list,
            current_datetime=local_now.strftime("%Y-%m-%d %H:%M (%A)"),
            module_instructions=module_instructions,
            context_block=context_block,
            history_str=history_str
        )
    
    async def get_rag_context(
        self,
        tenant_id: UUID,
        message: str
    ) -> str:
        """Retrieve relevant context from memory using semantic search."""
        if not self.enable_rag:
            return ""
        
        try:
            from app.services.embedding_service import EmbeddingService
            embedding_service = EmbeddingService(self.db)
            return await embedding_service.get_context_for_query(
                tenant_id=tenant_id,
                query=message,
                max_context_length=1500
            )
        except Exception as e:
            # RAG is optional, continue without context on error
            return ""
    
    async def classify_intent(
        self, 
        message: str, 
        modules: List[BaseModule],
        context: str = "",
        message_history: List[Dict[str, str]] = None,
        image_data: bytes = None
    ) -> Dict[str, Any]:
        """
        Classify user intent and extract data.
        Uses system_instruction for cleaner separation of roles.
        """
        module_ids = [m.module_id for m in modules]
        logger.info(f"Classifying intent with modules: {module_ids} for message: {message[:50]}...")
        
        system_prompt = self._build_system_prompt(modules, context, message_history)
        
        # Instantiate model with system instruction (Per-request instance)
        # This is cheap and ensures clean context without mixing roles in history
        config = {
            "temperature": 0.0,
            "top_p": 0.8,
            "top_k": 40
        }
        
        try:
            # Use instance model or create new one if system instruction supported (0.8.3+)
            model = genai.GenerativeModel(
                settings.gemini_model,
                system_instruction=system_prompt,
                generation_config=config
            )
            
            # Prepare User Input
            user_parts = [message]
            
            if image_data:
                # Add Vision Instruction
                user_parts[0] = f"""
                [IMAGE UPLOADED]
                –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ—Ç–ø—Ä–∞–≤–∏–ª —Ñ–æ—Ç–æ.
                1. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (—á–µ–∫, —Å—á–µ—Ç, –¥–æ–∫—É–º–µ–Ω—Ç?).
                2. –ò–∑–≤–ª–µ–∫–∏ –°–£–ú–ú–£, –î–ê–¢–£, –ö–ê–¢–ï–ì–û–†–ò–Æ.
                3. –ï—Å–ª–∏ —á–µ–∫ -> intent: 'expense'.
                4. –ï—Å–ª–∏ –ø—Ä–æ—Å—Ç–æ —Ñ–æ—Ç–æ -> –æ–ø–∏—à–∏.
                –¢–µ–∫—É—â–∏–π —Ç–µ–∫—Å—Ç: {message}
                """
                try:
                    image_part = {"mime_type": "image/jpeg", "data": image_data}
                    user_parts.append(image_part)
                except Exception as e:
                    logger.error(f"Failed to attach image: {e}")

            # Generate (Single turn, no history needed as it's in system prompt)
            response = await model.generate_content_async(user_parts)
            
            text = response.text.strip()
            logger.info(f"Gemini Raw Response: {text}")
            
            result = self._safe_parse_json(text)
            
            if result is None:
                logger.warning("Safe JSON parsing failed, using fallback classification")
                return self._fallback_classify(message, modules)
            
            # Metadata
            if hasattr(response, "usage_metadata"):
                result["_meta"] = {
                    "prompt_tokens": response.usage_metadata.prompt_token_count,
                    "response_tokens": response.usage_metadata.candidates_token_count,
                    "model": settings.gemini_model
                }
            
            # Override
            result = self._apply_whatsapp_priority(message, result, modules)
            return result
            
        except Exception as e:
            logger.error(f"Gemini classification error: {e}")
            return self._fallback_classify(message, modules)
    
    def _fallback_classify(
        self, 
        message: str, 
        modules: List[BaseModule]
    ) -> Dict[str, Any]:
        """Keyword-based fallback classification."""
        message_lower = message.lower()
        
        # Check for meeting scheduling keywords (BUT exclude cancellation)
        schedule_keywords = ["–æ—Ä–≥–∞–Ω–∏–∑—É–π –≤—Å—Ç—Ä–µ—á—É", "–∑–∞–ø–ª–∞–Ω–∏—Ä—É–π", "–¥–æ–≥–æ–≤–æ—Ä–∏—Å—å –æ –≤—Å—Ç—Ä–µ—á–µ", 
                           "—Å–æ–≥–ª–∞—Å—É–π –≤—Ä–µ–º—è", "–∫–µ–∑–¥–µ—Å—É “±–π—ã–º–¥–∞—Å—Ç—ã—Ä"]
        
        cancel_keywords = ["—É–¥–∞–ª–∏—Ç—å", "–æ—Ç–º–µ–Ω–∏—Ç—å", "—É–±–µ—Ä–∏", "–∂–æ—é", "–±–æ–ª–¥—ã—Ä–º–∞—É", "–∞–ª—ã–ø —Ç–∞—Å—Ç–∞—É"]
        if any(kw in message_lower for kw in cancel_keywords) and "–≤—Å—Ç—Ä–µ—á" in message_lower:
             return {
                "reasoning": "–û–±–Ω–∞—Ä—É–∂–µ–Ω –∑–∞–ø—Ä–æ—Å –Ω–∞ —É–¥–∞–ª–µ–Ω–∏–µ –≤—Å—Ç—Ä–µ—á–∏ (–∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞)",
                "intents": [{"intent": "cancel_meeting", "confidence": 0.9, "data": {}}]
            }

        # Priority: WhatsApp Messaging
        wa_keywords = ["–Ω–∞–ø–∏—à–∏", "–æ—Ç–ø—Ä–∞–≤—å", "—Å–∫–∞–∂–∏", "–∂–∞–∑", "–∂—ñ–±–µ—Ä", "write", "send"]
        if any(message_lower.startswith(kw) or f" {kw} " in f" {message_lower} " for kw in wa_keywords):
            # Check if whatsapp module is enabled
            if any(m.module_id == "whatsapp" for m in modules):
                # Extract potential name simply (naive)
                return {
                    "reasoning": "–û–±–Ω–∞—Ä—É–∂–µ–Ω –ø—Ä—è–º–æ–π –∑–∞–ø—Ä–æ—Å –Ω–∞ –æ—Ç–ø—Ä–∞–≤–∫—É —Å–æ–æ–±—â–µ–Ω–∏—è (Priority)",
                    "intents": [{"intent": "whatsapp", "confidence": 0.95, "data": {"action": "send_message", "original_message": message}}]
                }

        if any(kw in message_lower for kw in schedule_keywords):
            return {
                "reasoning": "–û–±–Ω–∞—Ä—É–∂–µ–Ω –∑–∞–ø—Ä–æ—Å –Ω–∞ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—é –≤—Å—Ç—Ä–µ—á–∏",
                "intents": [{"intent": "schedule_meeting", "confidence": 0.8, "data": {"original_message": message}}]
            }
        
        # Check for recall keywords
        recall_keywords = ["–Ω–∞–ø–æ–º–Ω–∏", "–æ —á–µ–º –¥–æ–≥–æ–≤–æ—Ä–∏–ª–∏—Å—å", "—á—Ç–æ –±—ã–ª–æ", "–≤—Å–ø–æ–º–Ω–∏",
                          "–µ—Å–∫–µ —Ç“Ø—Å—ñ—Ä", "–Ω–µ –∫–µ–ª—ñ—Å—Ç—ñ–∫"]
        if any(kw in message_lower for kw in recall_keywords):
            return {
                "reasoning": "–û–±–Ω–∞—Ä—É–∂–µ–Ω –∑–∞–ø—Ä–æ—Å –Ω–∞ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏",
                "intents": [{"intent": "recall", "confidence": 0.7, "data": {"query": message}}]
            }
        
        # Collect ALL matching intents (multi-intent support in fallback)
        matched_intents = []
        
        for module in modules:
            keywords = module.get_intent_keywords()
            score = sum(1 for kw in keywords if kw.lower() in message_lower)
            
            if score >= 1:
                matched_intents.append({
                    "intent": module.module_id,
                    "confidence": min(0.3 + (score * 0.1), 0.7),
                    "data": {}
                })
        
        if matched_intents:
            return {
                "reasoning": f"–ù–∞–π–¥–µ–Ω–æ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º: {', '.join([i['intent'] for i in matched_intents])}",
                "intents": matched_intents
            }
        
        return {
            "reasoning": "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –Ω–∞–º–µ—Ä–µ–Ω–∏–µ",
            "intents": [{"intent": "unknown", "confidence": 0.0, "data": {}}]
        }
    
    async def process_message(
        self,
        message: str,
        tenant_id: UUID,
        user_id: Optional[UUID] = None,
        enabled_modules: Optional[List[BaseModule]] = None,
        source: str = "web",
        silent_response: bool = False,
        image_data: bytes = None,
        on_status: Optional[Callable[[str], Awaitable[None]]] = None
    ) -> ModuleResponse:
        """
        Process a user message end-to-end (Unified Pipeline 2.0).
        1. Setup Tracing
        2. Get Context & History
        3. Classify Intent
        4. Execute Modules
        5. Save History
        """
        # Initialize tracing
        tracing = TracingService(self.db)
        trace = tracing.start_trace(
            tenant_id=tenant_id,
            user_message=message,
            user_id=user_id,
            source=source
        )
        
        try:
            # 1. Get Enabled Modules
            trace.start_step("get_modules")
            if not enabled_modules:
                registry = get_registry()
                enabled_modules = await registry.get_enabled_modules(self.db, tenant_id)
            
            if not enabled_modules:
                trace.log_error("NoModules", "No enabled modules found")
                return ModuleResponse(success=False, message=t("bot.error", self.language))
            trace.end_step("get_modules", {"count": len(enabled_modules)})

            # 2. Get History (Last 5 messages)
            message_history = []
            trace.start_step("get_history")
            try:
                from sqlalchemy import select, desc
                from app.models.chat import Message as ChatMessageModel # Renamed from Message to avoid conflict if any
                
                # Fetch recent history for context
                stmt = select(ChatMessageModel).where(
                    ChatMessageModel.tenant_id == tenant_id
                ).order_by(desc(ChatMessageModel.created_at)).limit(5)
                
                result = await self.db.execute(stmt)
                db_msgs = result.scalars().all()
                for m in reversed(db_msgs):
                    message_history.append({
                        "role": "user" if m.is_user else "assistant", 
                        "content": m.content
                    })
                trace.end_step("get_history", {"count": len(message_history)})
            except Exception as e:
                # CRITICAL: Rollback to clear the corrupted transaction state
                try:
                    await self.db.rollback()
                except Exception:
                    pass  # Ignore rollback errors
                trace.log_step("get_history_error", error=str(e))
                trace.end_step("get_history", {"error": str(e)})

            # 3. RAG Retrieval
            trace.start_step("rag_retrieval")
            context = await self.get_rag_context(tenant_id, message)
            trace.end_step("rag_retrieval", {"length": len(context)})
            trace.log_rag(context)
            
            # 4. Classification
            if on_status: await on_status("ü§î –î—É–º–∞—é...")
            trace.start_step("classify")
            classification = await self.classify_intent(
                message, enabled_modules, context, message_history, image_data
            )
            
            # Log Gemini Usage
            meta = classification.pop("_meta", None)
            if meta:
                trace.log_gemini_request(
                    prompt="[System Prompt Hidden]", # Too long to log fully
                    response_text=str(classification),
                    model=meta.get("model"),
                    prompt_tokens=meta.get("prompt_tokens"),
                    response_tokens=meta.get("response_tokens")
                )
            trace.end_step("classify")

            # Log reasoning
            reasoning = classification.get("reasoning", "")
            intents = classification.get("intents", [])
            trace.log_intent_classification(intents, reasoning)
            logger.info(f"[{trace.trace_id}] AI Reasoning: {reasoning}")
            logger.info(f"[{trace.trace_id}] Intents: {intents}")
            print(f"üéØ INTENTS: {intents}")
            print(f"üí≠ REASONING: {reasoning}")
            
            # If no intents or unknown - route to assistant for general conversation
            if not intents:
                intents = [{"intent": "assistant", "confidence": 0.5, "data": {"action": "chat"}}]
            elif len(intents) == 1 and intents[0].get("intent") == "unknown":
                intents = [{"intent": "assistant", "confidence": 0.5, "data": {"action": "chat"}}]

            # 5. Execution
            if on_status: await on_status("‚ö° –í—ã–ø–æ–ª–Ω—è—é...")
            
            # STRATEGIC FIX: Reset transaction before writes 
            # Read operations (history, RAG) might have failed silently, 
            # corrupting the transaction. This ensures modules start clean.
            try:
                await self.db.rollback()
            except Exception:
                pass  # OK if no active transaction
            
            all_responses = []
            registry = get_registry()
            for item in intents:
                intent = item.get("intent")
                data = item.get("data", {})
                confidence = item.get("confidence", 0.0)
                
                # Skip low confidence
                if confidence < 0.3: continue
                
                trace.start_step(f"exec_{intent}")
                
                # Special Handlers
                if intent == "recall":
                    resp = await self._handle_recall(tenant_id, message, context)
                    all_responses.append(resp.message)
                    trace.end_step(f"exec_{intent}", {"status": "recall_done"})
                    continue
                    
                if intent == "cancel_meeting":
                    msg = "–§—É–Ω–∫—Ü–∏—è –æ—Ç–º–µ–Ω—ã –≤—Å—Ç—Ä–µ—á –ø–æ–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞."
                    all_responses.append(msg)
                    continue

                # Module Execution
                module = registry.get(intent)
                if module and module in enabled_modules:
                    instance = type(module)(self.db)
                    
                    # Inject context
                    data["rag_context"] = context
                    data["original_message"] = message
                    data["on_status"] = on_status  # Pass status callback
                    
                    # Show module-specific status
                    if on_status:
                        status_map = {
                            "assistant": "üîç –ò—â—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é...",
                            "task": "üìã –†–∞–±–æ—Ç–∞—é —Å –∑–∞–¥–∞—á–∞–º–∏...",
                            "contacts": "üìí –†–∞–±–æ—Ç–∞—é —Å –∫–æ–Ω—Ç–∞–∫—Ç–∞–º–∏...",
                            "finance": "üí∞ –†–∞–±–æ—Ç–∞—é —Å —Ñ–∏–Ω–∞–Ω—Å–∞–º–∏...",
                            "meeting": "üìÖ –†–∞–±–æ—Ç–∞—é —Å –≤—Å—Ç—Ä–µ—á–∞–º–∏...",
                        }
                        status_text = status_map.get(intent, f"‚ö° {intent}...")
                        await on_status(status_text)
                    
                    # NOTE: Removed preemptive rollback - it was causing module data to be lost
                    # Rollback only happens on error (see except block below)
                    
                    # Remove on_status before processing (not serializable for trace)
                    data.pop("on_status", None)
                    
                    try:
                        resp = await instance.process(data, tenant_id, user_id, self.language)
                        if resp.message:
                            all_responses.append(resp.message)
                        elif not resp.success:
                             all_responses.append(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –º–æ–¥—É–ª—è {intent}")
                    except Exception as e:
                        # CRITICAL: Rollback to clear potentially corrupted transaction
                        try:
                            await self.db.rollback()
                        except Exception:
                            pass  # Ignore rollback errors
                        logger.error(f"Module {intent} failed: {e}")
                        all_responses.append(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")
                
                trace.end_step(f"exec_{intent}")

            # 6. Finalize Response
            combined_message = "\n\n".join(all_responses)
            if not combined_message:
                 combined_message = t("bot.unknown_intent", self.language)

            trace.set_final_response(combined_message, success=True)
            
            # Store conversation as memory (async, non-blocking)
            # 1. Store in Vector DB (RAG)
            await self._store_conversation_memory(
                tenant_id, user_id, message, combined_message
            )
            
            if not silent_response:
                # 2. Store in Relational DB (Chat History)
                try:
                    from app.models.chat import Message
                    
                    # User message
                    user_msg = Message(
                        tenant_id=tenant_id,
                        user_id=user_id,
                        is_user=True,
                        content=message,
                        intent="user_input",
                        created_at=datetime.now()
                    )
                    self.db.add(user_msg)
                    
                    # Dual-Write: Unified Interaction (User) - DISABLED FOR DEBUGGING
                    # try:
                    #     async with self.db.begin_nested():
                    #         from app.models.interaction import UnifiedInteraction, InteractionSource, InteractionRole
                    #         user_interaction = UnifiedInteraction(
                    #             tenant_id=tenant_id,
                    #             user_id=user_id,
                    #             session_id=f"web:{user_id or 'anon'}",
                    #             source=InteractionSource.WEB.value,
                    #             role=InteractionRole.USER.value,
                    #             content=message,
                    #             metadata_={"intent": "user_input"},
                    #             created_at=user_msg.created_at
                    #         )
                    #         self.db.add(user_interaction)
                    #         await self.db.flush()
                    # except Exception as e:
                    #     logger.error(f"Dual-Write User Failed: {e}")

                    # Bot response (1 second later to ensure order)
                    from datetime import timedelta
                    bot_msg = Message(
                        tenant_id=tenant_id,
                        user_id=user_id,
                        is_user=False,
                        content=combined_message,
                        intent=",".join([i.get("intent", "") for i in intents]),
                        created_at=datetime.now() + timedelta(seconds=1)
                    )
                    self.db.add(bot_msg)
                    
                    # Dual-Write: Unified Interaction (Bot) - DISABLED FOR DEBUGGING
                    # try:
                    #     async with self.db.begin_nested():
                    #         bot_interaction = UnifiedInteraction(
                    #             tenant_id=tenant_id,
                    #             user_id=user_id,
                    #             session_id=f"web:{user_id or 'anon'}",
                    #             source=InteractionSource.WEB.value,
                    #             role=InteractionRole.ASSISTANT.value,
                    #             content=combined_message,
                    #             metadata_={"intents": intents},
                    #             created_at=bot_msg.created_at
                    #         )
                    #         self.db.add(bot_interaction)
                    #         await self.db.flush()
                    # except Exception as e:
                    #     logger.error(f"Dual-Write Bot Failed: {e}")
                    
                    # We rely on the caller (TelegramBotService) to commit, or we can flush here
                    await self.db.flush()
                except Exception as e:
                    # CRITICAL: Rollback to clear the corrupted transaction state
                    try:
                        await self.db.rollback()
                    except Exception:
                        pass  # Ignore rollback errors
                    import logging
                    logging.getLogger(__name__).error(f"Failed to save chat history: {e}")
            
            return ModuleResponse(success=True, message=combined_message)

        except Exception as e:
            trace.log_error("CriticalPipelineError", str(e))
            return ModuleResponse(success=False, message=f"–°–∏—Å—Ç–µ–º–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
        finally:
            await trace.save()
    
    async def _handle_schedule_meeting(
        self,
        tenant_id: UUID,
        user_id: UUID,
        message: str,
        data: dict
    ) -> ModuleResponse:
        """Handle meeting scheduling with autonomous negotiation."""
        try:
            from app.services.meeting_negotiator import MeetingNegotiator
            from app.services.whatsapp_bot import WhatsAppBotService
            from app.models.tenant import Tenant
            
            # Get tenant for WhatsApp credentials
            tenant = await self.db.get(Tenant, tenant_id)
            if not tenant or not tenant.greenapi_instance_id:
                return ModuleResponse(
                    success=False,
                    message="–î–ª—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è –≤—Å—Ç—Ä–µ—á –Ω—É–∂–Ω–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ WhatsApp."
                )
            
            whatsapp = WhatsAppBotService()
            negotiator = MeetingNegotiator(
                self.db, whatsapp, language=self.language
            )
            
            # Extract contact name and meeting title from data or message
            contact_name = data.get("contact_name") or data.get("attendee_name")
            meeting_title = data.get("meeting_title") or data.get("title", "–í—Å—Ç—Ä–µ—á–∞")
            
            if not contact_name:
                # Try to extract from message
                # This is a simple extraction, AI should ideally do this
                return ModuleResponse(
                    success=False,
                    message="–° –∫–µ–º —Ö–æ—Ç–∏—Ç–µ –≤—Å—Ç—Ä–µ—Ç–∏—Ç—å—Å—è? –£—Ç–æ—á–Ω–∏—Ç–µ –∏–º—è –∫–æ–Ω—Ç–∞–∫—Ç–∞."
                )
            
            result = await negotiator.initiate_negotiation(
                tenant_id=tenant_id,
                initiator_user_id=user_id,
                contact_name=contact_name,
                meeting_title=meeting_title,
                whatsapp_instance_id=tenant.greenapi_instance_id,
                whatsapp_token=tenant.greenapi_token
            )
            
            if result.get("need_phone"):
                return ModuleResponse(
                    success=False,
                    message=result.get("message", "–ö–æ–Ω—Ç–∞–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω.")
                )
            
            return ModuleResponse(
                success=True,
                message=result.get("message", "–û—Ç–ø—Ä–∞–≤–∏–ª –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –æ –≤—Å—Ç—Ä–µ—á–µ.")
            )
            
        except Exception as e:
            return ModuleResponse(
                success=False,
                message=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–∏ –≤—Å—Ç—Ä–µ—á–∏: {str(e)}"
            )
    
    async def _handle_recall(
        self,
        tenant_id: UUID,
        message: str,
        context: str
    ) -> ModuleResponse:
        """Handle recall/memory query."""
        if not context:
            if self.language == "kz":
                return ModuleResponse(
                    success=True,
                    message="”®–∫—ñ–Ω—ñ—à–∫–µ –æ—Ä–∞–π, –æ—Å—ã —Ç–∞“õ—ã—Ä—ã–ø –±–æ–π—ã–Ω—à–∞ –∞“õ–ø–∞—Ä–∞—Ç —Ç–∞–ø–ø–∞–¥—ã–º."
                )
            else:
                return ModuleResponse(
                    success=True,
                    message="–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –Ω–µ –Ω–∞—à—ë–ª –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É –≤ –ø–∞–º—è—Ç–∏."
                )
        
        # Use AI to format the context into a natural response
        if self.model:
            try:
                prompt = f"""
–ù–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –ø–∞–º—è—Ç–∏, –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

–í–æ–ø—Ä–æ—Å: {message}

–ù–∞–π–¥–µ–Ω–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:
{context}

–û—Ç–≤–µ—Ç—å –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É, —Ü–∏—Ç–∏—Ä—É—è –∏—Å—Ç–æ—á–Ω–∏–∫–∏.
"""
                response = self.model.generate_content(prompt)
                return ModuleResponse(
                    success=True,
                    message=response.text.strip()
                )
            except:
                pass
        
        # Fallback: return raw context
        if self.language == "kz":
            return ModuleResponse(
                success=True,
                message=f"–ú–µ–Ω –º—ã–Ω–∞–Ω—ã —Ç–∞–ø—Ç—ã–º:\n\n{context}"
            )
        else:
            return ModuleResponse(
                success=True,
                message=f"–í–æ—Ç —á—Ç–æ —è –Ω–∞—à—ë–ª:\n\n{context}"
            )
    
    async def _store_conversation_memory(
        self,
        tenant_id: UUID,
        user_id:Optional[ UUID ],
        user_message: str,
        bot_response: str
    ) -> None:
        """Store conversation as memory for future RAG queries."""
        try:
            from app.services.embedding_service import EmbeddingService
            
            embedding_service = EmbeddingService(self.db)
            await embedding_service.store_conversation_memory(
                tenant_id=tenant_id,
                user_message=user_message,
                bot_response=bot_response,
                user_id=user_id,
                source="chat"
            )
        except Exception:
            # Memory storage is optional, don't fail on error
            pass
